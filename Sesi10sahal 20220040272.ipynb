{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUtphuhbxIyZ"
      },
      "source": [
        "Nama : Moh. sahal assahari\n",
        "\n",
        "Kelas : TI22j\n",
        "\n",
        "Sesi : 10\n",
        "\n",
        "Nim : 20220040272\n",
        "\n",
        "Matkul : Machine Learning\n",
        "\n",
        "Dosen : Bu Ivana Lucia Kharisma, M.Kom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKI7Bq2fyol4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\SAHAL ASY'ARI\\AppData\\Local\\Microsoft\\WindowsApps\\python3.11.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/SAHAL ASY'ARI/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o5KTo3x-lhB"
      },
      "source": [
        "1. Kode di atas menginstal beberapa paket dan library yang diperlukan untuk membuat virtual display yang tidak terlihat (invisible) dengan ukuran 1400x900 piksel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb8W0fXDypPR"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\SAHAL ASY'ARI\\AppData\\Local\\Microsoft\\WindowsApps\\python3.11.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/SAHAL ASY'ARI/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMmsi-23-qX5"
      },
      "source": [
        "2. Perintah di atas digunakan untuk menginstal paket-paket Python \"imageio\" dan \"imageio_ffmpeg\" menggunakan pip, yang diperlukan untuk bekerja dengan citra dan video dalam Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj8eO2aLyrSX",
        "outputId": "a65670e2-9095-4041-8088-4d03cd138164"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFHe-zv--tS5"
      },
      "source": [
        "3. Kode di atas mengimpor library numpy untuk operasi numerik, library gym untuk reinforcement learning environment, serta library random dan time untuk penggunaan fungsi-fungsi terkait randomization dan waktu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcEEi1feytto",
        "outputId": "d92f8644-f45d-4059-9b88-a5137b77fe82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_map = [\n",
        "    \"SFFFF\",\n",
        "    \"FHFHF\",\n",
        "    \"FFFHF\",\n",
        "    \"HFFHF\",\n",
        "    \"FFFGF\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BD6Dtim-04h"
      },
      "source": [
        "4. Kode di atas membuat lingkungan FrozenLake dengan peta kustom yang didefinisikan dalam variabel `my_map`, menonaktifkan efek licin pada lingkungan, merender lingkungan, dan mengatur ulang lingkungan untuk memulai episode baru."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdQrKST2y_nE",
        "outputId": "72c9ed90-be63-4581-8d8d-a5108f05f6fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 25\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfs8e0np-3rh"
      },
      "source": [
        "5. Kode di atas menghitung ukuran ruang aksi dan ruang keadaan dari lingkungan, serta membuat tabel Q kosong dengan ukuran yang sesuai, kemudian mencetak nilai-nilai tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE2BmlIDzBKa"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkZ4Gaga-7bT"
      },
      "source": [
        "6. Kode di atas mendefinisikan parameter-parameter pelatihan seperti jumlah episode, maksimum langkah per episode, tingkat pembelajaran, tingkat diskon, tingkat eksplorasi awal, tingkat eksplorasi maksimum, tingkat eksplorasi minimum, dan tingkat penurunan eksplorasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSeghGzLzEMK",
        "outputId": "88667e89-fa67-4922-e1ba-437879cfab70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 0 step\n",
            "Delta Q = 0.901578435511469\n",
            "Q_table[0,1]_old = 0.01525801408380424\n",
            "Q_table[(0, 1)]_new = 0.01531064818689279\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 1 step\n",
            "Delta Q = 0.9016561008400492\n",
            "Q_table[5,3]_old = 0.01594379304514116\n",
            "Q_table[(5, 3)]_new = 0.016005514580676224\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 2 step\n",
            "Delta Q = 0.9016561008400492\n",
            "Q_table[0,3]_old = 0.016407090346212627\n",
            "Q_table[(0, 3)]_new = 0.016422482151640543\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 3 step\n",
            "Delta Q = 0.9016561008400492\n",
            "Q_table[0,3]_old = 0.016422482151640543\n",
            "Q_table[(0, 3)]_new = 0.016436334776525667\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 4 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[0,1]_old = 0.01531064818689279\n",
            "Q_table[(0, 1)]_new = 0.015364129311690459\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 5 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[5,0]_old = 0.014244982650346748\n",
            "Q_table[(5, 0)]_new = 0.01440503032879902\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 6 step\n",
            "Delta Q = 0.9014285289198181\n",
            "Q_table[5,1]_old = 0.013727073993478072\n",
            "Q_table[(5, 1)]_new = 0.013782895513948255\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 7 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[10,3]_old = 0.012709912458173683\n",
            "Q_table[(10, 3)]_new = 0.013023467155843262\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 0 step\n",
            "Delta Q = 0.9016878704371082\n",
            "Q_table[0,2]_old = 0.016728291313628067\n",
            "Q_table[(0, 2)]_new = 0.016743332619373455\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 1 step\n",
            "Delta Q = 0.9018118509883566\n",
            "Q_table[1,2]_old = 0.017049196334426187\n",
            "Q_table[(1, 2)]_new = 0.01715612768934016\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 2 step\n",
            "Delta Q = 0.9018118509883566\n",
            "Q_table[2,3]_old = 0.01620383909567823\n",
            "Q_table[(2, 3)]_new = 0.016395306174466998\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 3 step\n",
            "Delta Q = 0.9019864247811302\n",
            "Q_table[2,1]_old = 0.018301525134915075\n",
            "Q_table[(2, 1)]_new = 0.018457797402553752\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 4 step\n",
            "Delta Q = 0.9018273219428529\n",
            "Q_table[7,3]_old = 0.010125808212703931\n",
            "Q_table[(7, 3)]_new = 0.01094054933428636\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 5 step\n",
            "Delta Q = 0.9016984566412447\n",
            "Q_table[2,0]_old = 0.013948758050404523\n",
            "Q_table[(2, 0)]_new = 0.014252338886608748\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 6 step\n",
            "Delta Q = 0.901657589929318\n",
            "Q_table[1,0]_old = 0.01603263803428499\n",
            "Q_table[(1, 0)]_new = 0.016086964160174463\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 7 step\n",
            "Delta Q = 0.901657589929318\n",
            "Q_table[0,3]_old = 0.016436334776525667\n",
            "Q_table[(0, 3)]_new = 0.016450291228191073\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 8 step\n",
            "Delta Q = 0.901657589929318\n",
            "Q_table[0,3]_old = 0.016450291228191073\n",
            "Q_table[(0, 3)]_new = 0.01646285203468994\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 9 step\n",
            "Delta Q = 0.9016984566412447\n",
            "Q_table[0,2]_old = 0.016743332619373455\n",
            "Q_table[(0, 2)]_new = 0.016767455998680784\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 10 step\n",
            "Delta Q = 0.9018273219428529\n",
            "Q_table[1,2]_old = 0.01715612768934016\n",
            "Q_table[(1, 2)]_new = 0.017267836863258966\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 11 step\n",
            "Delta Q = 0.9013228192454118\n",
            "Q_table[2,2]_old = 0.010339250574173278\n",
            "Q_table[(2, 2)]_new = 0.010628144762167696\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 12 step\n",
            "Delta Q = 0.900355713799515\n",
            "Q_table[3,2]_old = 0.001387814967856505\n",
            "Q_table[(3, 2)]_new = 0.001604747270585802\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 13 step\n",
            "Delta Q = 0.900355713799515\n",
            "Q_table[4,3]_old = 0.0006924462468689879\n",
            "Q_table[(4, 3)]_new = 0.0009789154216970366\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 14 step\n",
            "Delta Q = 0.9013228192454118\n",
            "Q_table[4,0]_old = 0.003593068681969166\n",
            "Q_table[(4, 0)]_new = 0.004556581059183995\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 15 step\n",
            "Delta Q = 0.9004511015248592\n",
            "Q_table[3,2]_old = 0.001604747270585802\n",
            "Q_table[(3, 2)]_new = 0.0018953740683864374\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 16 step\n",
            "Delta Q = 0.9013228192454118\n",
            "Q_table[4,0]_old = 0.004556581059183995\n",
            "Q_table[(4, 0)]_new = 0.005423742198677341\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 17 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 0 step\n",
            "Delta Q = 0.9016599781438694\n",
            "Q_table[0,3]_old = 0.01646285203468994\n",
            "Q_table[(0, 3)]_new = 0.01647654497509034\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 1 step\n",
            "Delta Q = 0.9017095158494627\n",
            "Q_table[0,2]_old = 0.016767455998680784\n",
            "Q_table[(0, 2)]_new = 0.016800226248275346\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 0 step\n",
            "Delta Q = 0.9017095158494627\n",
            "Q_table[0,2]_old = 0.016800226248275346\n",
            "Q_table[(0, 2)]_new = 0.01682971947291045\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 1 step\n",
            "Delta Q = 0.9016661422278182\n",
            "Q_table[1,0]_old = 0.016086964160174463\n",
            "Q_table[(1, 0)]_new = 0.01614440997197515\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 2 step\n",
            "Delta Q = 0.9016661422278182\n",
            "Q_table[0,0]_old = 0.016318897237443668\n",
            "Q_table[(0, 0)]_new = 0.016353149741517435\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 3 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[0,1]_old = 0.015364129311690459\n",
            "Q_table[(0, 1)]_new = 0.01541226232400836\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 0 step\n",
            "Delta Q = 0.9016661422278182\n",
            "Q_table[0,3]_old = 0.01647654497509034\n",
            "Q_table[(0, 3)]_new = 0.01649503270539944\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 1 step\n",
            "Delta Q = 0.9016661422278182\n",
            "Q_table[0,3]_old = 0.01649503270539944\n",
            "Q_table[(0, 3)]_new = 0.01651167166267763\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 2 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[0,1]_old = 0.01541226232400836\n",
            "Q_table[(0, 1)]_new = 0.01545558203509447\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 3 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[5,0]_old = 0.01440503032879902\n",
            "Q_table[(5, 0)]_new = 0.014549073239406065\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 4 step\n",
            "Delta Q = 0.9014285289198181\n",
            "Q_table[5,1]_old = 0.013782895513948255\n",
            "Q_table[(5, 1)]_new = 0.013833134882371421\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 5 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[10,3]_old = 0.013023467155843262\n",
            "Q_table[(10, 3)]_new = 0.013305666383745883\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 6 step\n",
            "Delta Q = 0.9015845459434869\n",
            "Q_table[5,0]_old = 0.014549073239406065\n",
            "Q_table[(5, 0)]_new = 0.014678711858952405\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 7 step\n",
            "Delta Q = 0.9016661422278182\n",
            "Q_table[5,3]_old = 0.016005514580676224\n",
            "Q_table[(5, 3)]_new = 0.016071105350426735\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 8 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.01545558203509447\n",
            "Q_table[(0, 1)]_new = 0.01550106326127727\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 0 step\n",
            "Delta Q = 0.9016661422278182\n",
            "Q_table[0,3]_old = 0.01651167166267763\n",
            "Q_table[(0, 3)]_new = 0.016526646724228003\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 1 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.01550106326127727\n",
            "Q_table[(0, 1)]_new = 0.015541996364841791\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 2 step\n",
            "Delta Q = 0.9014285289198181\n",
            "Q_table[5,1]_old = 0.013833134882371421\n",
            "Q_table[(5, 1)]_new = 0.01387835031395227\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 0 step\n",
            "Delta Q = 0.9017095158494627\n",
            "Q_table[0,2]_old = 0.01682971947291045\n",
            "Q_table[(0, 2)]_new = 0.016856263375082045\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 1 step\n",
            "Delta Q = 0.9016687700741332\n",
            "Q_table[1,0]_old = 0.01614440997197515\n",
            "Q_table[(1, 0)]_new = 0.016198739048910758\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 2 step\n",
            "Delta Q = 0.9017095158494627\n",
            "Q_table[0,2]_old = 0.016856263375082045\n",
            "Q_table[(0, 2)]_new = 0.016880152887036478\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 3 step\n",
            "Delta Q = 0.9016711351358166\n",
            "Q_table[1,0]_old = 0.016198739048910758\n",
            "Q_table[(1, 0)]_new = 0.016250000279836294\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 4 step\n",
            "Delta Q = 0.9016711351358166\n",
            "Q_table[0,3]_old = 0.016526646724228003\n",
            "Q_table[(0, 3)]_new = 0.016545117187621815\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 5 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.015541996364841791\n",
            "Q_table[(0, 1)]_new = 0.01557883615804986\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 6 step\n",
            "Delta Q = 0.9014285289198181\n",
            "Q_table[5,1]_old = 0.01387835031395227\n",
            "Q_table[(5, 1)]_new = 0.013919044202375034\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 7 step\n",
            "Delta Q = 0.9016061268269674\n",
            "Q_table[10,2]_old = 0.01442958504866658\n",
            "Q_table[(10, 2)]_new = 0.014592753370767311\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,3]_old = 0.0\n",
            "Q_table[(11, 3)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 0 step\n",
            "Delta Q = 0.9016711351358166\n",
            "Q_table[0,0]_old = 0.016353149741517435\n",
            "Q_table[(0, 0)]_new = 0.016388969903182303\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 1 step\n",
            "Delta Q = 0.9016711351358166\n",
            "Q_table[0,0]_old = 0.016388969903182303\n",
            "Q_table[(0, 0)]_new = 0.016421208048680684\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 2 step\n",
            "Delta Q = 0.9016711351358166\n",
            "Q_table[0,0]_old = 0.016421208048680684\n",
            "Q_table[(0, 0)]_new = 0.016450222379629228\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 3 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.01557883615804986\n",
            "Q_table[(0, 1)]_new = 0.01561199197193712\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 4 step\n",
            "Delta Q = 0.901444682583706\n",
            "Q_table[5,1]_old = 0.013919044202375034\n",
            "Q_table[(5, 1)]_new = 0.013971822365843493\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 5 step\n",
            "Delta Q = 0.901444682583706\n",
            "Q_table[10,0]_old = 0.011919972420064302\n",
            "Q_table[(10, 0)]_new = 0.012172657761763836\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 6 step\n",
            "Delta Q = 0.901444682583706\n",
            "Q_table[10,0]_old = 0.012172657761763836\n",
            "Q_table[(10, 0)]_new = 0.012400074569293415\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 7 step\n",
            "Delta Q = 0.9016061268269674\n",
            "Q_table[10,2]_old = 0.014592753370767311\n",
            "Q_table[(10, 2)]_new = 0.01473960486065797\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 8 step\n",
            "Delta Q = 0.9014592208812051\n",
            "Q_table[11,0]_old = 0.007465767037761302\n",
            "Q_table[(11, 0)]_new = 0.00817841121519031\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 0 step\n",
            "Delta Q = 0.9017095158494627\n",
            "Q_table[0,2]_old = 0.016880152887036478\n",
            "Q_table[(0, 2)]_new = 0.01690165344779547\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 1 step\n",
            "Delta Q = 0.9016732636913318\n",
            "Q_table[1,0]_old = 0.016250000279836294\n",
            "Q_table[(1, 0)]_new = 0.016298263943184416\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 2 step\n",
            "Delta Q = 0.9016732636913318\n",
            "Q_table[0,0]_old = 0.016450222379629228\n",
            "Q_table[(0, 0)]_new = 0.016478463832998055\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 3 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.01561199197193712\n",
            "Q_table[(0, 1)]_new = 0.015641832204435654\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 4 step\n",
            "Delta Q = 0.9014592208812051\n",
            "Q_table[5,1]_old = 0.013971822365843493\n",
            "Q_table[(5, 1)]_new = 0.014033861010464282\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 5 step\n",
            "Delta Q = 0.9016061268269674\n",
            "Q_table[10,2]_old = 0.01473960486065797\n",
            "Q_table[(10, 2)]_new = 0.014871771201559563\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 6 step\n",
            "Delta Q = 0.9014723053489544\n",
            "Q_table[11,0]_old = 0.00817841121519031\n",
            "Q_table[(11, 0)]_new = 0.008832875442625676\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 7 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[10,3]_old = 0.013305666383745883\n",
            "Q_table[(10, 3)]_new = 0.013566139175063541\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 8 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[5,0]_old = 0.014678711858952405\n",
            "Q_table[(5, 0)]_new = 0.01480188010274941\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 9 step\n",
            "Delta Q = 0.9014723053489544\n",
            "Q_table[5,1]_old = 0.014033861010464282\n",
            "Q_table[(5, 1)]_new = 0.014102780258372251\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 10 step\n",
            "Delta Q = 0.9016061268269674\n",
            "Q_table[10,2]_old = 0.014871771201559563\n",
            "Q_table[(10, 2)]_new = 0.014990720908370997\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 11 step\n",
            "Delta Q = 0.9025412477064301\n",
            "Q_table[11,2]_old = 0.015482755754019965\n",
            "Q_table[(11, 2)]_new = 0.016475727885048065\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 12 step\n",
            "Delta Q = 0.9019864247811302\n",
            "Q_table[12,3]_old = 0.010304988467553861\n",
            "Q_table[(12, 3)]_new = 0.011260914401928663\n",
            "We are on 12 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 13 step\n",
            "Delta Q = 0.9018273219428529\n",
            "Q_table[7,3]_old = 0.01094054933428636\n",
            "Q_table[(7, 3)]_new = 0.011673816343710546\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 14 step\n",
            "Delta Q = 0.9019864247811302\n",
            "Q_table[2,1]_old = 0.018457797402553752\n",
            "Q_table[(2, 1)]_new = 0.018598442443428564\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 15 step\n",
            "Delta Q = 0.9025412477064301\n",
            "Q_table[7,1]_old = 0.020064896779092796\n",
            "Q_table[(7, 1)]_new = 0.020599654807613617\n",
            "We are on 7 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 16 step\n",
            "Delta Q = 0.90401360751\n",
            "Q_table[12,1]_old = 0.02566916875181917\n",
            "Q_table[(12, 1)]_new = 0.027115859386637256\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 17 step\n",
            "Delta Q = 0.9026108435828836\n",
            "Q_table[17,0]_old = 0.010976288272538028\n",
            "Q_table[(17, 0)]_new = 0.012489503028167795\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 18 step\n",
            "Delta Q = 0.9016310970606198\n",
            "Q_table[16,3]_old = 0.005086014542500707\n",
            "Q_table[(16, 3)]_new = 0.006208510148870395\n",
            "We are on 16 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 19 step\n",
            "Delta Q = 0.9026108435828836\n",
            "Q_table[11,1]_old = 0.016223503302700906\n",
            "Q_table[(11, 1)]_new = 0.017211996555314385\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 20 step\n",
            "Delta Q = 0.9059953020831\n",
            "Q_table[16,1]_old = 0.02637215740286434\n",
            "Q_table[(16, 1)]_new = 0.029730243745677905\n",
            "We are on 16 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 21 step\n",
            "Delta Q = 0.9029432941308221\n",
            "Q_table[21,3]_old = 0.005521192172470737\n",
            "Q_table[(21, 3)]_new = 0.007912367086045775\n",
            "We are on 21 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 22 step\n",
            "Delta Q = 0.9059953020831\n",
            "Q_table[16,1]_old = 0.029730243745677905\n",
            "Q_table[(16, 1)]_new = 0.032752521454210114\n",
            "We are on 16 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 23 step\n",
            "Delta Q = 0.91881\n",
            "Q_table[21,2]_old = 0.060558606900000006\n",
            "Q_table[(21, 2)]_new = 0.07331274621\n",
            "We are on 21 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 24 step\n",
            "Delta Q = 0.91881\n",
            "Q_table[22,1]_old = 0.060558606900000006\n",
            "Q_table[(22, 1)]_new = 0.07331274621\n",
            "We are on 22 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 25 step\n",
            "Delta Q = 0.90401360751\n",
            "Q_table[22,3]_old = 0.013456195721100002\n",
            "Q_table[(22, 3)]_new = 0.01612418365899\n",
            "We are on 22 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 26 step\n",
            "Delta Q = 0.91881\n",
            "Q_table[17,1]_old = 0.040541490000000006\n",
            "Q_table[(17, 1)]_new = 0.05529734100000001\n",
            "We are on 17 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 27 step\n",
            "Delta Q = 0.91881\n",
            "Q_table[22,1]_old = 0.07331274621\n",
            "Q_table[(22, 1)]_new = 0.084791471589\n",
            "We are on 22 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 28 step\n",
            "Delta Q = 0.91881\n",
            "Q_table[22,1]_old = 0.084791471589\n",
            "Q_table[(22, 1)]_new = 0.09512232443009999\n",
            "We are on 22 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 29 step\n",
            "Delta Q = 1.0\n",
            "Q_table[22,2]_old = 0.19\n",
            "Q_table[(22, 2)]_new = 0.271\n",
            "We are on 22 state\n",
            "And now we are on 23 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 0 step\n",
            "Delta Q = 0.9017095158494627\n",
            "Q_table[0,2]_old = 0.01690165344779547\n",
            "Q_table[(0, 2)]_new = 0.01692100395247856\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 1 step\n",
            "Delta Q = 0.9018412458018995\n",
            "Q_table[1,2]_old = 0.017267836863258966\n",
            "Q_table[(1, 2)]_new = 0.0173822989788325\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 2 step\n",
            "Delta Q = 0.9020393658259538\n",
            "Q_table[2,1]_old = 0.018598442443428564\n",
            "Q_table[(2, 1)]_new = 0.018777964025039458\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 3 step\n",
            "Delta Q = 0.9026844700792771\n",
            "Q_table[7,1]_old = 0.020599654807613617\n",
            "Q_table[(7, 1)]_new = 0.021224159406129345\n",
            "We are on 7 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 4 step\n",
            "Delta Q = 0.9017039876589762\n",
            "Q_table[12,0]_old = 0.006587751529464831\n",
            "Q_table[(12, 0)]_new = 0.007632964035494472\n",
            "We are on 12 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 5 step\n",
            "Delta Q = 0.9032424996239669\n",
            "Q_table[11,1]_old = 0.017211996555314385\n",
            "Q_table[(11, 1)]_new = 0.01873329652374975\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 6 step\n",
            "Delta Q = 0.90725796187479\n",
            "Q_table[16,1]_old = 0.032752521454210114\n",
            "Q_table[(16, 1)]_new = 0.0367352311835791\n",
            "We are on 16 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 7 step\n",
            "Delta Q = 0.9036367878871744\n",
            "Q_table[21,3]_old = 0.007912367086045775\n",
            "Q_table[(21, 3)]_new = 0.01075791826461553\n",
            "We are on 21 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 8 step\n",
            "Delta Q = 0.90725796187479\n",
            "Q_table[16,1]_old = 0.0367352311835791\n",
            "Q_table[(16, 1)]_new = 0.040319669940011196\n",
            "We are on 16 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 9 step\n",
            "Delta Q = 0.9017933323256938\n",
            "Q_table[21,0]_old = 0.005027869164978497\n",
            "Q_table[(21, 0)]_new = 0.006318414574174446\n",
            "We are on 21 state\n",
            "And now we are on 20 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 10 step\n",
            "Delta Q = 0.9017933323256938\n",
            "Q_table[20,1]_old = 0.007080723123188377\n",
            "Q_table[(20, 1)]_new = 0.008165983136563339\n",
            "We are on 20 state\n",
            "And now we are on 20 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 11 step\n",
            "Delta Q = 0.9017933323256938\n",
            "Q_table[20,1]_old = 0.008165983136563339\n",
            "Q_table[(20, 1)]_new = 0.009142717148600805\n",
            "We are on 20 state\n",
            "And now we are on 20 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 12 step\n",
            "Delta Q = 0.9017933323256938\n",
            "Q_table[20,0]_old = 0.00393490620350002\n",
            "Q_table[(20, 0)]_new = 0.005334747908843817\n",
            "We are on 20 state\n",
            "And now we are on 20 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 13 step\n",
            "Delta Q = 0.9017933323256938\n",
            "Q_table[20,0]_old = 0.005334747908843817\n",
            "Q_table[(20, 0)]_new = 0.006594605443653235\n",
            "We are on 20 state\n",
            "And now we are on 20 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 14 step\n",
            "Delta Q = 0.90725796187479\n",
            "Q_table[20,2]_old = 0.018114467936301004\n",
            "Q_table[(20, 2)]_new = 0.023560983017460905\n",
            "We are on 20 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 15 step\n",
            "Delta Q = 0.926829\n",
            "Q_table[21,2]_old = 0.07331274621\n",
            "Q_table[(21, 2)]_new = 0.09281047158900001\n",
            "We are on 21 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 16 step\n",
            "Delta Q = 0.926829\n",
            "Q_table[22,1]_old = 0.09512232443009999\n",
            "Q_table[(22, 1)]_new = 0.11243909198709\n",
            "We are on 22 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 17 step\n",
            "Delta Q = 0.909188236687311\n",
            "Q_table[22,0]_old = 0.009913025430000002\n",
            "Q_table[(22, 0)]_new = 0.018109959574311003\n",
            "We are on 22 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 18 step\n",
            "Delta Q = 0.926829\n",
            "Q_table[21,2]_old = 0.09281047158900001\n",
            "Q_table[(21, 2)]_new = 0.11035842443010001\n",
            "We are on 21 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 19 step\n",
            "Delta Q = 0.9109254840185799\n",
            "Q_table[22,0]_old = 0.018109959574311003\n",
            "Q_table[(22, 0)]_new = 0.027224447635459805\n",
            "We are on 22 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 20 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[21,3]_old = 0.01075791826461553\n",
            "Q_table[(21, 3)]_new = 0.013673773762215083\n",
            "We are on 21 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 21 step\n",
            "Delta Q = 0.905474436759\n",
            "Q_table[16,2]_old = 0.019706695358149805\n",
            "Q_table[(16, 2)]_new = 0.023210462581334825\n",
            "We are on 16 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 22 step\n",
            "Delta Q = 0.9026844700792771\n",
            "Q_table[17,3]_old = 0.00802506678596336\n",
            "Q_table[(17, 3)]_new = 0.009907030186644112\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 23 step\n",
            "Delta Q = 0.905474436759\n",
            "Q_table[12,1]_old = 0.027115859386637256\n",
            "Q_table[(12, 1)]_new = 0.02987871020697353\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 24 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[17,0]_old = 0.012489503028167795\n",
            "Q_table[(17, 0)]_new = 0.015232200049412125\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 25 step\n",
            "Delta Q = 0.9\n",
            "Q_table[16,0]_old = 0.0\n",
            "Q_table[(16, 0)]_new = 0.0\n",
            "We are on 16 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 0 step\n",
            "Delta Q = 0.9017208475989045\n",
            "Q_table[0,2]_old = 0.01692100395247856\n",
            "Q_table[(0, 2)]_new = 0.016949751156135125\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 1 step\n",
            "Delta Q = 0.9016780253644574\n",
            "Q_table[1,0]_old = 0.016298263943184416\n",
            "Q_table[(1, 0)]_new = 0.016346462913323354\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 2 step\n",
            "Delta Q = 0.9017208475989045\n",
            "Q_table[0,2]_old = 0.016949751156135125\n",
            "Q_table[(0, 2)]_new = 0.01697562363942603\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 3 step\n",
            "Delta Q = 0.9018590184384789\n",
            "Q_table[1,2]_old = 0.0173822989788325\n",
            "Q_table[(1, 2)]_new = 0.017503087519428157\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 4 step\n",
            "Delta Q = 0.9018590184384789\n",
            "Q_table[2,3]_old = 0.016395306174466998\n",
            "Q_table[(2, 3)]_new = 0.016614793995499207\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 5 step\n",
            "Delta Q = 0.9021011917812068\n",
            "Q_table[2,1]_old = 0.018777964025039458\n",
            "Q_table[(2, 1)]_new = 0.01900135940374232\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 0 step\n",
            "Delta Q = 0.9016805867403032\n",
            "Q_table[0,3]_old = 0.016545117187621815\n",
            "Q_table[(0, 3)]_new = 0.01657119220916281\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 1 step\n",
            "Delta Q = 0.9016805867403032\n",
            "Q_table[0,0]_old = 0.016478463832998055\n",
            "Q_table[(0, 0)]_new = 0.016511204190001426\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 2 step\n",
            "Delta Q = 0.9016805867403032\n",
            "Q_table[0,3]_old = 0.01657119220916281\n",
            "Q_table[(0, 3)]_new = 0.016594659728549708\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 3 step\n",
            "Delta Q = 0.9016805867403032\n",
            "Q_table[0,0]_old = 0.016511204190001426\n",
            "Q_table[(0, 0)]_new = 0.01654067051130446\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 4 step\n",
            "Delta Q = 0.9017328056644234\n",
            "Q_table[0,2]_old = 0.01697562363942603\n",
            "Q_table[(0, 2)]_new = 0.017010866939906815\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 5 step\n",
            "Delta Q = 0.9018811345809705\n",
            "Q_table[1,2]_old = 0.017503087519428157\n",
            "Q_table[(1, 2)]_new = 0.01763391334845583\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 6 step\n",
            "Delta Q = 0.9017457574214971\n",
            "Q_table[2,0]_old = 0.014252338886608748\n",
            "Q_table[(2, 0)]_new = 0.014572862419445002\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 7 step\n",
            "Delta Q = 0.9018811345809705\n",
            "Q_table[1,2]_old = 0.01763391334845583\n",
            "Q_table[(1, 2)]_new = 0.01775165659458074\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 8 step\n",
            "Delta Q = 0.9021011917812068\n",
            "Q_table[2,1]_old = 0.01900135940374232\n",
            "Q_table[(2, 1)]_new = 0.019202415244574896\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,2]_old = 0.0\n",
            "Q_table[(7, 2)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 0 step\n",
            "Delta Q = 0.9016840758270508\n",
            "Q_table[0,3]_old = 0.016594659728549708\n",
            "Q_table[(0, 3)]_new = 0.01661926958274551\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 1 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.015641832204435654\n",
            "Q_table[(0, 1)]_new = 0.015668688413684337\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 2 step\n",
            "Delta Q = 0.9014840813699287\n",
            "Q_table[5,1]_old = 0.014102780258372251\n",
            "Q_table[(5, 1)]_new = 0.014176583602463754\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 3 step\n",
            "Delta Q = 0.9018545963558513\n",
            "Q_table[10,2]_old = 0.014990720908370997\n",
            "Q_table[(10, 2)]_new = 0.015346245173385124\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 4 step\n",
            "Delta Q = 0.9029579923104905\n",
            "Q_table[11,2]_old = 0.016475727885048065\n",
            "Q_table[(11, 2)]_new = 0.017786147407033638\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 5 step\n",
            "Delta Q = 0.905474436759\n",
            "Q_table[12,1]_old = 0.02987871020697353\n",
            "Q_table[(12, 1)]_new = 0.032365275945276176\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 6 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[17,0]_old = 0.015232200049412125\n",
            "Q_table[(17, 0)]_new = 0.01770062736853202\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 7 step\n",
            "Delta Q = 0.9018545963558513\n",
            "Q_table[16,3]_old = 0.006208510148870395\n",
            "Q_table[(16, 3)]_new = 0.007442255489834581\n",
            "We are on 16 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 8 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[11,1]_old = 0.01873329652374975\n",
            "Q_table[(11, 1)]_new = 0.020851614195435884\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[16,0]_old = 0.0\n",
            "Q_table[(16, 0)]_new = 0.0\n",
            "We are on 16 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 0 step\n",
            "Delta Q = 0.9016840758270508\n",
            "Q_table[0,0]_old = 0.01654067051130446\n",
            "Q_table[(0, 0)]_new = 0.01657067928722479\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 1 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[0,1]_old = 0.015668688413684337\n",
            "Q_table[(0, 1)]_new = 0.01569285900200815\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 2 step\n",
            "Delta Q = 0.9015192782721652\n",
            "Q_table[5,1]_old = 0.014176583602463754\n",
            "Q_table[(5, 1)]_new = 0.014278203514382507\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 3 step\n",
            "Delta Q = 0.9015192782721652\n",
            "Q_table[10,0]_old = 0.012400074569293415\n",
            "Q_table[(10, 0)]_new = 0.012679345384529202\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 4 step\n",
            "Delta Q = 0.9020643098053481\n",
            "Q_table[10,2]_old = 0.015346245173385124\n",
            "Q_table[(10, 2)]_new = 0.015875930461394763\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 5 step\n",
            "Delta Q = 0.9015717171156781\n",
            "Q_table[11,0]_old = 0.008832875442625676\n",
            "Q_table[(11, 0)]_new = 0.00952130501404119\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 6 step\n",
            "Delta Q = 0.9015910394296923\n",
            "Q_table[10,3]_old = 0.013566139175063541\n",
            "Q_table[(10, 3)]_new = 0.013800564687249436\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 7 step\n",
            "Delta Q = 0.9016840758270508\n",
            "Q_table[5,3]_old = 0.016071105350426735\n",
            "Q_table[(5, 3)]_new = 0.016148070642434835\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 8 step\n",
            "Delta Q = 0.9016840758270508\n",
            "Q_table[0,3]_old = 0.01661926958274551\n",
            "Q_table[(0, 3)]_new = 0.016641418451521735\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 9 step\n",
            "Delta Q = 0.9017574140028635\n",
            "Q_table[0,2]_old = 0.017010866939906815\n",
            "Q_table[(0, 2)]_new = 0.017067194248779626\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 0 step\n",
            "Delta Q = 0.9016896522306292\n",
            "Q_table[0,0]_old = 0.01657067928722479\n",
            "Q_table[(0, 0)]_new = 0.016603263589131494\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 1 step\n",
            "Delta Q = 0.9016896522306292\n",
            "Q_table[0,3]_old = 0.016641418451521735\n",
            "Q_table[(0, 3)]_new = 0.016666928836998746\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 2 step\n",
            "Delta Q = 0.9016896522306292\n",
            "Q_table[0,0]_old = 0.016603263589131494\n",
            "Q_table[(0, 0)]_new = 0.016632589460847527\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 3 step\n",
            "Delta Q = 0.9017574140028635\n",
            "Q_table[0,2]_old = 0.017067194248779626\n",
            "Q_table[(0, 2)]_new = 0.017117888826765158\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 4 step\n",
            "Delta Q = 0.9016946709938498\n",
            "Q_table[1,0]_old = 0.016346462913323354\n",
            "Q_table[(1, 0)]_new = 0.016406487615840768\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 5 step\n",
            "Delta Q = 0.9016946709938498\n",
            "Q_table[0,3]_old = 0.016666928836998746\n",
            "Q_table[(0, 3)]_new = 0.016694906947148622\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 6 step\n",
            "Delta Q = 0.9016946709938498\n",
            "Q_table[0,0]_old = 0.016632589460847527\n",
            "Q_table[(0, 0)]_new = 0.016664001508612525\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 7 step\n",
            "Delta Q = 0.9017574140028635\n",
            "Q_table[0,2]_old = 0.017117888826765158\n",
            "Q_table[(0, 2)]_new = 0.017163513946952137\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 8 step\n",
            "Delta Q = 0.9019010391092129\n",
            "Q_table[1,2]_old = 0.01775165659458074\n",
            "Q_table[(1, 2)]_new = 0.01787753004433558\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 9 step\n",
            "Delta Q = 0.9017698754743892\n",
            "Q_table[2,0]_old = 0.014572862419445002\n",
            "Q_table[(2, 0)]_new = 0.014885451651889725\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 0 step\n",
            "Delta Q = 0.9016991878807483\n",
            "Q_table[0,0]_old = 0.016664001508612525\n",
            "Q_table[(0, 0)]_new = 0.016696789238499533\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 1 step\n",
            "Delta Q = 0.9017698754743892\n",
            "Q_table[0,2]_old = 0.017163513946952137\n",
            "Q_table[(0, 2)]_new = 0.017217038026646144\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 2 step\n",
            "Delta Q = 0.9017698754743892\n",
            "Q_table[1,3]_old = 0.01587411704215679\n",
            "Q_table[(1, 3)]_new = 0.016056580812330332\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 3 step\n",
            "Delta Q = 0.901704486764638\n",
            "Q_table[1,0]_old = 0.016406487615840768\n",
            "Q_table[(1, 0)]_new = 0.01647032561889466\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 4 step\n",
            "Delta Q = 0.901704486764638\n",
            "Q_table[0,3]_old = 0.016694906947148622\n",
            "Q_table[(0, 3)]_new = 0.01672990301707173\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 5 step\n",
            "Delta Q = 0.9017698754743892\n",
            "Q_table[0,2]_old = 0.017217038026646144\n",
            "Q_table[(0, 2)]_new = 0.017265209698370754\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 6 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[1,0]_old = 0.01647032561889466\n",
            "Q_table[(1, 0)]_new = 0.0165325488171439\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 7 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,3]_old = 0.01672990301707173\n",
            "Q_table[(0, 3)]_new = 0.016766168475503263\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 8 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[0,1]_old = 0.01569285900200815\n",
            "Q_table[(0, 1)]_new = 0.015722232095408385\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 9 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[5,0]_old = 0.01480188010274941\n",
            "Q_table[(5, 0)]_new = 0.014920351086075517\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 10 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[5,0]_old = 0.014920351086075517\n",
            "Q_table[(5, 0)]_new = 0.015026974971069015\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 11 step\n",
            "Delta Q = 0.9015717171156781\n",
            "Q_table[5,1]_old = 0.014278203514382507\n",
            "Q_table[(5, 1)]_new = 0.014422100278622339\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 12 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[10,3]_old = 0.013800564687249436\n",
            "Q_table[(10, 3)]_new = 0.014019167212125542\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 13 step\n",
            "Delta Q = 0.9015717171156781\n",
            "Q_table[5,1]_old = 0.014422100278622339\n",
            "Q_table[(5, 1)]_new = 0.014551607366438186\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 14 step\n",
            "Delta Q = 0.9015717171156781\n",
            "Q_table[10,0]_old = 0.012679345384529202\n",
            "Q_table[(10, 0)]_new = 0.012983127961754364\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 15 step\n",
            "Delta Q = 0.9020643098053481\n",
            "Q_table[10,2]_old = 0.015875930461394763\n",
            "Q_table[(10, 2)]_new = 0.01635264722060344\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 16 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[11,1]_old = 0.020851614195435884\n",
            "Q_table[(11, 1)]_new = 0.022758100099953403\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 17 step\n",
            "Delta Q = 0.9\n",
            "Q_table[16,0]_old = 0.0\n",
            "Q_table[(16, 0)]_new = 0.0\n",
            "We are on 16 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 0 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,3]_old = 0.016766168475503263\n",
            "Q_table[(0, 3)]_new = 0.01679880738809164\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 1 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,0]_old = 0.016696789238499533\n",
            "Q_table[(0, 0)]_new = 0.016736366074788286\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 2 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,3]_old = 0.01679880738809164\n",
            "Q_table[(0, 3)]_new = 0.01682818240942118\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 3 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,0]_old = 0.016736366074788286\n",
            "Q_table[(0, 0)]_new = 0.01677198522744816\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 4 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,0]_old = 0.01677198522744816\n",
            "Q_table[(0, 0)]_new = 0.01680404246484205\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 5 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,3]_old = 0.01682818240942118\n",
            "Q_table[(0, 3)]_new = 0.016854619928617767\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 6 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,3]_old = 0.016854619928617767\n",
            "Q_table[(0, 3)]_new = 0.016878413695894694\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 7 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[0,1]_old = 0.015722232095408385\n",
            "Q_table[(0, 1)]_new = 0.015748667879468596\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 8 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[5,0]_old = 0.015026974971069015\n",
            "Q_table[(5, 0)]_new = 0.015122936467563162\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 0 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[0,1]_old = 0.015748667879468596\n",
            "Q_table[(0, 1)]_new = 0.015772460085122786\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 0 step\n",
            "Delta Q = 0.9017092557601387\n",
            "Q_table[0,3]_old = 0.016878413695894694\n",
            "Q_table[(0, 3)]_new = 0.01689982808644393\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 1 step\n",
            "Delta Q = 0.9017698754743892\n",
            "Q_table[0,2]_old = 0.017265209698370754\n",
            "Q_table[(0, 2)]_new = 0.0173085642029229\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 2 step\n",
            "Delta Q = 0.9017698754743892\n",
            "Q_table[1,3]_old = 0.016056580812330332\n",
            "Q_table[(1, 3)]_new = 0.01622079820548652\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 3 step\n",
            "Delta Q = 0.9019010391092129\n",
            "Q_table[1,2]_old = 0.01787753004433558\n",
            "Q_table[(1, 2)]_new = 0.017990816149114935\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 4 step\n",
            "Delta Q = 0.9017810907987625\n",
            "Q_table[2,0]_old = 0.014885451651889725\n",
            "Q_table[(2, 0)]_new = 0.015177997285463131\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 5 step\n",
            "Delta Q = 0.9019010391092129\n",
            "Q_table[1,2]_old = 0.017990816149114935\n",
            "Q_table[(1, 2)]_new = 0.018092773643416354\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 6 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[2,0]_old = 0.015177997285463131\n",
            "Q_table[(2, 0)]_new = 0.015451382147615038\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 7 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.01622079820548652\n",
            "Q_table[(1, 3)]_new = 0.01638990297563609\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 8 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.01638990297563609\n",
            "Q_table[(1, 3)]_new = 0.0165420972687707\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 0 step\n",
            "Delta Q = 0.901598658993601\n",
            "Q_table[0,1]_old = 0.015772460085122786\n",
            "Q_table[(0, 1)]_new = 0.015793873070211555\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 1 step\n",
            "Delta Q = 0.9017135478560894\n",
            "Q_table[5,3]_old = 0.016148070642434835\n",
            "Q_table[(5, 3)]_new = 0.01624681143428072\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 2 step\n",
            "Delta Q = 0.9016084343319938\n",
            "Q_table[0,1]_old = 0.015793873070211555\n",
            "Q_table[(0, 1)]_new = 0.01582292009518419\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 3 step\n",
            "Delta Q = 0.9017135478560894\n",
            "Q_table[5,3]_old = 0.01624681143428072\n",
            "Q_table[(5, 3)]_new = 0.016335678146942013\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 4 step\n",
            "Delta Q = 0.9017135478560894\n",
            "Q_table[0,3]_old = 0.01689982808644393\n",
            "Q_table[(0, 3)]_new = 0.016923393133888905\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 5 step\n",
            "Delta Q = 0.9017135478560894\n",
            "Q_table[0,3]_old = 0.016923393133888905\n",
            "Q_table[(0, 3)]_new = 0.016944601676589382\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 6 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.0173085642029229\n",
            "Q_table[(0, 2)]_new = 0.01736889237332883\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 7 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[1,0]_old = 0.0165325488171439\n",
            "Q_table[(1, 0)]_new = 0.016598814280389063\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 8 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[0,1]_old = 0.01582292009518419\n",
            "Q_table[(0, 1)]_new = 0.015857860222213034\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 9 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[5,0]_old = 0.015122936467563162\n",
            "Q_table[(5, 0)]_new = 0.015227874957354105\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 10 step\n",
            "Delta Q = 0.9016189120748398\n",
            "Q_table[5,1]_old = 0.014551607366438186\n",
            "Q_table[(5, 1)]_new = 0.01471535870463411\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 0 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[0,1]_old = 0.015857860222213034\n",
            "Q_table[(0, 1)]_new = 0.01588930633653899\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 0 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.016944601676589382\n",
            "Q_table[(0, 3)]_new = 0.016969661853889997\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 1 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[0,1]_old = 0.01588930633653899\n",
            "Q_table[(0, 1)]_new = 0.01591760783943235\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 2 step\n",
            "Delta Q = 0.9016189120748398\n",
            "Q_table[5,1]_old = 0.01471535870463411\n",
            "Q_table[(5, 1)]_new = 0.014862734909010439\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 3 step\n",
            "Delta Q = 0.9022530519098954\n",
            "Q_table[10,2]_old = 0.01635264722060344\n",
            "Q_table[(10, 2)]_new = 0.016970434408438484\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 4 step\n",
            "Delta Q = 0.9016800730064354\n",
            "Q_table[11,0]_old = 0.00952130501404119\n",
            "Q_table[(11, 0)]_new = 0.010249247519072482\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 5 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[10,3]_old = 0.014019167212125542\n",
            "Q_table[(10, 3)]_new = 0.014234482627460247\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 0 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[0,1]_old = 0.01591760783943235\n",
            "Q_table[(0, 1)]_new = 0.015943079192036375\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 1 step\n",
            "Delta Q = 0.9016800730064354\n",
            "Q_table[5,1]_old = 0.014862734909010439\n",
            "Q_table[(5, 1)]_new = 0.015056534424544805\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 2 step\n",
            "Delta Q = 0.9016800730064354\n",
            "Q_table[10,0]_old = 0.012983127961754364\n",
            "Q_table[(10, 0)]_new = 0.013364888172014339\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 3 step\n",
            "Delta Q = 0.9022530519098954\n",
            "Q_table[10,2]_old = 0.016970434408438484\n",
            "Q_table[(10, 2)]_new = 0.01752644287749002\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 4 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[11,1]_old = 0.022758100099953403\n",
            "Q_table[(11, 1)]_new = 0.02447393741401917\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 5 step\n",
            "Delta Q = 0.905474436759\n",
            "Q_table[16,2]_old = 0.023210462581334825\n",
            "Q_table[(16, 2)]_new = 0.026363853082201343\n",
            "We are on 16 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 6 step\n",
            "Delta Q = 0.926829\n",
            "Q_table[17,1]_old = 0.05529734100000001\n",
            "Q_table[(17, 1)]_new = 0.0765966069\n",
            "We are on 17 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 7 step\n",
            "Delta Q = 0.9075830640831\n",
            "Q_table[22,3]_old = 0.01612418365899\n",
            "Q_table[(22, 3)]_new = 0.022094829376191002\n",
            "We are on 22 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 8 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[17,0]_old = 0.01770062736853202\n",
            "Q_table[(17, 0)]_new = 0.019922211955739927\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 9 step\n",
            "Delta Q = 0.9024229198039879\n",
            "Q_table[16,3]_old = 0.007442255489834581\n",
            "Q_table[(16, 3)]_new = 0.00912094974483902\n",
            "We are on 16 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,3]_old = 0.0\n",
            "Q_table[(11, 3)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 0 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.016969661853889997\n",
            "Q_table[(0, 3)]_new = 0.016992216013460553\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 1 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[0,1]_old = 0.015943079192036375\n",
            "Q_table[(0, 1)]_new = 0.015966003409379998\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 2 step\n",
            "Delta Q = 0.9017351178448715\n",
            "Q_table[5,1]_old = 0.015056534424544805\n",
            "Q_table[(5, 1)]_new = 0.015285998826961838\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 3 step\n",
            "Delta Q = 0.9016172321365473\n",
            "Q_table[10,3]_old = 0.014234482627460247\n",
            "Q_table[(10, 3)]_new = 0.014428266501261482\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 4 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[5,3]_old = 0.016335678146942013\n",
            "Q_table[(5, 3)]_new = 0.016421630677207366\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 5 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.016992216013460553\n",
            "Q_table[(0, 3)]_new = 0.017012514757074052\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 6 step\n",
            "Delta Q = 0.9016257414370435\n",
            "Q_table[0,1]_old = 0.015966003409379998\n",
            "Q_table[(0, 1)]_new = 0.015995144505485528\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 7 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[5,3]_old = 0.016421630677207366\n",
            "Q_table[(5, 3)]_new = 0.016498987954446185\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 8 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017012514757074052\n",
            "Q_table[(0, 3)]_new = 0.0170307836263262\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 9 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.0170307836263262\n",
            "Q_table[(0, 3)]_new = 0.017047225608653134\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 10 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017047225608653134\n",
            "Q_table[(0, 3)]_new = 0.017062023392747375\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 11 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017062023392747375\n",
            "Q_table[(0, 3)]_new = 0.01707534139843219\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 12 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.01707534139843219\n",
            "Q_table[(0, 3)]_new = 0.017087327603548527\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 13 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017087327603548527\n",
            "Q_table[(0, 3)]_new = 0.017098115188153226\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 14 step\n",
            "Delta Q = 0.9016333998074902\n",
            "Q_table[0,1]_old = 0.015995144505485528\n",
            "Q_table[(0, 1)]_new = 0.016029029862427147\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 15 step\n",
            "Delta Q = 0.9017351178448715\n",
            "Q_table[5,1]_old = 0.015285998826961838\n",
            "Q_table[(5, 1)]_new = 0.015492516789137167\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 16 step\n",
            "Delta Q = 0.9016333998074902\n",
            "Q_table[10,3]_old = 0.014428266501261482\n",
            "Q_table[(10, 3)]_new = 0.014618839658625506\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 17 step\n",
            "Delta Q = 0.9016333998074902\n",
            "Q_table[5,0]_old = 0.015227874957354105\n",
            "Q_table[(5, 0)]_new = 0.015338487269108867\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 18 step\n",
            "Delta Q = 0.9017351178448715\n",
            "Q_table[5,1]_old = 0.015492516789137167\n",
            "Q_table[(5, 1)]_new = 0.015678382955094963\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 19 step\n",
            "Delta Q = 0.9017351178448715\n",
            "Q_table[10,0]_old = 0.013364888172014339\n",
            "Q_table[(10, 0)]_new = 0.013763517199684418\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 20 step\n",
            "Delta Q = 0.9017351178448715\n",
            "Q_table[10,0]_old = 0.013763517199684418\n",
            "Q_table[(10, 0)]_new = 0.014122283324587488\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 21 step\n",
            "Delta Q = 0.9024229198039879\n",
            "Q_table[10,2]_old = 0.01752644287749002\n",
            "Q_table[(10, 2)]_new = 0.018196718393728918\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 22 step\n",
            "Delta Q = 0.9018014751209792\n",
            "Q_table[11,0]_old = 0.010249247519072482\n",
            "Q_table[(11, 0)]_new = 0.011025797888144397\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 23 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 0 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,0]_old = 0.01680404246484205\n",
            "Q_table[(0, 0)]_new = 0.016843158563317397\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 1 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017098115188153226\n",
            "Q_table[(0, 3)]_new = 0.017107824014297456\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 2 step\n",
            "Delta Q = 0.9016333998074902\n",
            "Q_table[0,1]_old = 0.016029029862427147\n",
            "Q_table[(0, 1)]_new = 0.016059526683674604\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 0 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017107824014297456\n",
            "Q_table[(0, 3)]_new = 0.017116561957827264\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 1 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,0]_old = 0.016843158563317397\n",
            "Q_table[(0, 0)]_new = 0.016878363051945212\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 2 step\n",
            "Delta Q = 0.9016333998074902\n",
            "Q_table[0,1]_old = 0.016059526683674604\n",
            "Q_table[(0, 1)]_new = 0.016086973822797317\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 3 step\n",
            "Delta Q = 0.9016333998074902\n",
            "Q_table[5,0]_old = 0.015338487269108867\n",
            "Q_table[(5, 0)]_new = 0.015438038349688153\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 4 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[5,3]_old = 0.016498987954446185\n",
            "Q_table[(5, 3)]_new = 0.01656860950396112\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 5 step\n",
            "Delta Q = 0.9016402923408922\n",
            "Q_table[0,1]_old = 0.016086973822797317\n",
            "Q_table[(0, 1)]_new = 0.016118568781409735\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 0 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.017116561957827264\n",
            "Q_table[(0, 3)]_new = 0.01712442610700409\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 1 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,0]_old = 0.016878363051945212\n",
            "Q_table[(0, 0)]_new = 0.016910047091710245\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 2 step\n",
            "Delta Q = 0.9017195203449596\n",
            "Q_table[0,3]_old = 0.01712442610700409\n",
            "Q_table[(0, 3)]_new = 0.017131503841263235\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 3 step\n",
            "Delta Q = 0.9016402923408922\n",
            "Q_table[0,1]_old = 0.016118568781409735\n",
            "Q_table[(0, 1)]_new = 0.016147004244160913\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 0 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.01736889237332883\n",
            "Q_table[(0, 2)]_new = 0.01742318772669417\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 0 step\n",
            "Delta Q = 0.9016402923408922\n",
            "Q_table[0,1]_old = 0.016147004244160913\n",
            "Q_table[(0, 1)]_new = 0.016172596160636973\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 1 step\n",
            "Delta Q = 0.9016402923408922\n",
            "Q_table[5,0]_old = 0.015438038349688153\n",
            "Q_table[(5, 0)]_new = 0.01553452685561149\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 2 step\n",
            "Delta Q = 0.9017248955849427\n",
            "Q_table[5,3]_old = 0.01656860950396112\n",
            "Q_table[(5, 3)]_new = 0.016636644138507732\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 3 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.01742318772669417\n",
            "Q_table[(0, 2)]_new = 0.01747205354472297\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 4 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.0165420972687707\n",
            "Q_table[(1, 3)]_new = 0.01667907213259185\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 0 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.01747205354472297\n",
            "Q_table[(0, 2)]_new = 0.01751603278094889\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 1 step\n",
            "Delta Q = 0.901734087245314\n",
            "Q_table[1,0]_old = 0.016598814280389063\n",
            "Q_table[(1, 0)]_new = 0.016673020097664096\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 2 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.01751603278094889\n",
            "Q_table[(0, 2)]_new = 0.01755561409355222\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 0 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.01755561409355222\n",
            "Q_table[(0, 2)]_new = 0.017591237274895213\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 1 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.01667907213259185\n",
            "Q_table[(1, 3)]_new = 0.016802349510030887\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 2 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.016802349510030887\n",
            "Q_table[(1, 3)]_new = 0.016913299149726016\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 0 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[0,2]_old = 0.017591237274895213\n",
            "Q_table[(0, 2)]_new = 0.017623298138103913\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 1 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.016913299149726016\n",
            "Q_table[(1, 3)]_new = 0.017013153825451634\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 2 step\n",
            "Delta Q = 0.9017911845906983\n",
            "Q_table[1,3]_old = 0.017013153825451634\n",
            "Q_table[(1, 3)]_new = 0.01710302303360469\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 3 step\n",
            "Delta Q = 0.9019010391092129\n",
            "Q_table[1,2]_old = 0.018092773643416354\n",
            "Q_table[(1, 2)]_new = 0.018184535388287633\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 4 step\n",
            "Delta Q = 0.9013228192454118\n",
            "Q_table[2,2]_old = 0.010628144762167696\n",
            "Q_table[(2, 2)]_new = 0.010888149531362672\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 5 step\n",
            "Delta Q = 0.9019010391092129\n",
            "Q_table[3,0]_old = 0.0133618105597146\n",
            "Q_table[(3, 0)]_new = 0.013926668612956055\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 6 step\n",
            "Delta Q = 0.9021011917812068\n",
            "Q_table[2,1]_old = 0.019202415244574896\n",
            "Q_table[(2, 1)]_new = 0.019383365501324214\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,2]_old = 0.0\n",
            "Q_table[(7, 2)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 0 step\n",
            "Delta Q = 0.9018002690034405\n",
            "Q_table[0,2]_old = 0.017623298138103913\n",
            "Q_table[(0, 2)]_new = 0.017661237327733996\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 0 step\n",
            "Delta Q = 0.9017484624954457\n",
            "Q_table[0,3]_old = 0.017131503841263235\n",
            "Q_table[(0, 3)]_new = 0.017166815952582577\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 1 step\n",
            "Delta Q = 0.9017484624954457\n",
            "Q_table[0,3]_old = 0.017166815952582577\n",
            "Q_table[(0, 3)]_new = 0.017198596852769987\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 2 step\n",
            "Delta Q = 0.9017484624954457\n",
            "Q_table[0,3]_old = 0.017198596852769987\n",
            "Q_table[(0, 3)]_new = 0.017227199662938654\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 3 step\n",
            "Delta Q = 0.9016470277697123\n",
            "Q_table[0,1]_old = 0.016172596160636973\n",
            "Q_table[(0, 1)]_new = 0.016202364314285542\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 4 step\n",
            "Delta Q = 0.9018014751209792\n",
            "Q_table[5,1]_old = 0.015678382955094963\n",
            "Q_table[(5, 1)]_new = 0.01591201978056463\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 5 step\n",
            "Delta Q = 0.9018014751209792\n",
            "Q_table[10,0]_old = 0.014122283324587488\n",
            "Q_table[(10, 0)]_new = 0.014511530113107903\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 6 step\n",
            "Delta Q = 0.9016470277697123\n",
            "Q_table[10,3]_old = 0.014618839658625506\n",
            "Q_table[(10, 3)]_new = 0.014803983462475221\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 7 step\n",
            "Delta Q = 0.9018014751209792\n",
            "Q_table[5,1]_old = 0.01591201978056463\n",
            "Q_table[(5, 1)]_new = 0.01612229292348733\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 8 step\n",
            "Delta Q = 0.9016470277697123\n",
            "Q_table[10,3]_old = 0.014803983462475221\n",
            "Q_table[(10, 3)]_new = 0.014970612885939965\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 9 step\n",
            "Delta Q = 0.9017484624954457\n",
            "Q_table[5,3]_old = 0.016636644138507732\n",
            "Q_table[(5, 3)]_new = 0.016721442220102623\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 10 step\n",
            "Delta Q = 0.9017484624954457\n",
            "Q_table[0,3]_old = 0.017227199662938654\n",
            "Q_table[(0, 3)]_new = 0.017252942192090455\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 11 step\n",
            "Delta Q = 0.9017484624954457\n",
            "Q_table[0,3]_old = 0.017252942192090455\n",
            "Q_table[(0, 3)]_new = 0.017276110468327076\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 12 step\n",
            "Delta Q = 0.9018002690034405\n",
            "Q_table[0,2]_old = 0.017661237327733996\n",
            "Q_table[(0, 2)]_new = 0.017695382598401074\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 13 step\n",
            "Delta Q = 0.9018002690034405\n",
            "Q_table[1,3]_old = 0.01710302303360469\n",
            "Q_table[(1, 3)]_new = 0.017192989733684695\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 14 step\n",
            "Delta Q = 0.9017518428772417\n",
            "Q_table[1,0]_old = 0.016673020097664096\n",
            "Q_table[(1, 0)]_new = 0.016757560965139393\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 15 step\n",
            "Delta Q = 0.9017518428772417\n",
            "Q_table[0,3]_old = 0.017276110468327076\n",
            "Q_table[(0, 3)]_new = 0.017300342298736074\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 16 step\n",
            "Delta Q = 0.9018002690034405\n",
            "Q_table[0,2]_old = 0.017695382598401074\n",
            "Q_table[(0, 2)]_new = 0.017726113342001443\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 17 step\n",
            "Delta Q = 0.9019189531846311\n",
            "Q_table[1,2]_old = 0.018184535388287633\n",
            "Q_table[(1, 2)]_new = 0.018285035034089965\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 18 step\n",
            "Delta Q = 0.9019189531846311\n",
            "Q_table[2,3]_old = 0.016614793995499207\n",
            "Q_table[(2, 3)]_new = 0.016872267780580385\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 19 step\n",
            "Delta Q = 0.9019189531846311\n",
            "Q_table[2,3]_old = 0.016872267780580385\n",
            "Q_table[(2, 3)]_new = 0.017103994187153443\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 20 step\n",
            "Delta Q = 0.901810218468375\n",
            "Q_table[2,0]_old = 0.015451382147615038\n",
            "Q_table[(2, 0)]_new = 0.01571646240122844\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 21 step\n",
            "Delta Q = 0.9019189531846311\n",
            "Q_table[1,2]_old = 0.018285035034089965\n",
            "Q_table[(1, 2)]_new = 0.018375484715312064\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 22 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[2,0]_old = 0.01571646240122844\n",
            "Q_table[(2, 0)]_new = 0.015963989147921492\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 23 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[1,3]_old = 0.017192989733684695\n",
            "Q_table[(1, 3)]_new = 0.017292863747132122\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 24 step\n",
            "Delta Q = 0.9017548852208581\n",
            "Q_table[1,0]_old = 0.016757560965139393\n",
            "Q_table[(1, 0)]_new = 0.016836690089483596\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 25 step\n",
            "Delta Q = 0.9017548852208581\n",
            "Q_table[0,3]_old = 0.017300342298736074\n",
            "Q_table[(0, 3)]_new = 0.01732519328972061\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 26 step\n",
            "Delta Q = 0.9017548852208581\n",
            "Q_table[0,3]_old = 0.01732519328972061\n",
            "Q_table[(0, 3)]_new = 0.017347559181606693\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 27 step\n",
            "Delta Q = 0.9017548852208581\n",
            "Q_table[0,3]_old = 0.017347559181606693\n",
            "Q_table[(0, 3)]_new = 0.01736768848430417\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 28 step\n",
            "Delta Q = 0.9016554227797902\n",
            "Q_table[0,1]_old = 0.016202364314285542\n",
            "Q_table[(0, 1)]_new = 0.01623755066264715\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 29 step\n",
            "Delta Q = 0.9016554227797902\n",
            "Q_table[5,0]_old = 0.01553452685561149\n",
            "Q_table[(5, 0)]_new = 0.0156364969498405\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 30 step\n",
            "Delta Q = 0.9018014751209792\n",
            "Q_table[5,1]_old = 0.01612229292348733\n",
            "Q_table[(5, 1)]_new = 0.01631153875211776\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 31 step\n",
            "Delta Q = 0.9024229198039879\n",
            "Q_table[10,2]_old = 0.018196718393728918\n",
            "Q_table[(10, 2)]_new = 0.018799966358343925\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 32 step\n",
            "Delta Q = 0.9018611966694761\n",
            "Q_table[11,0]_old = 0.011025797888144397\n",
            "Q_table[(11, 0)]_new = 0.011784414768806005\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 33 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 0 step\n",
            "Delta Q = 0.9016554227797902\n",
            "Q_table[0,1]_old = 0.01623755066264715\n",
            "Q_table[(0, 1)]_new = 0.016269218376172595\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 1 step\n",
            "Delta Q = 0.9017548852208581\n",
            "Q_table[5,3]_old = 0.016721442220102623\n",
            "Q_table[(5, 3)]_new = 0.016804183218950504\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 2 step\n",
            "Delta Q = 0.9016636141386761\n",
            "Q_table[0,1]_old = 0.016269218376172595\n",
            "Q_table[(0, 1)]_new = 0.016305910677231437\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 3 step\n",
            "Delta Q = 0.9018611966694761\n",
            "Q_table[5,1]_old = 0.01631153875211776\n",
            "Q_table[(5, 1)]_new = 0.016541581546382033\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 4 step\n",
            "Delta Q = 0.9016636141386761\n",
            "Q_table[10,3]_old = 0.014970612885939965\n",
            "Q_table[(10, 3)]_new = 0.015137165736022067\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 5 step\n",
            "Delta Q = 0.9018611966694761\n",
            "Q_table[5,1]_old = 0.016541581546382033\n",
            "Q_table[(5, 1)]_new = 0.01674862006121988\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 6 step\n",
            "Delta Q = 0.9024229198039879\n",
            "Q_table[10,2]_old = 0.018799966358343925\n",
            "Q_table[(10, 2)]_new = 0.01934288952649743\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 7 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[11,0]_old = 0.011784414768806005\n",
            "Q_table[(11, 0)]_new = 0.01252091935504865\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 0 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017726113342001443\n",
            "Q_table[(0, 2)]_new = 0.017772674994617193\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 1 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[1,3]_old = 0.017292863747132122\n",
            "Q_table[(1, 3)]_new = 0.017382750359234804\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 0 step\n",
            "Delta Q = 0.9017594948244672\n",
            "Q_table[0,3]_old = 0.01736768848430417\n",
            "Q_table[(0, 3)]_new = 0.017390414460340856\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 1 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017772674994617193\n",
            "Q_table[(0, 2)]_new = 0.01781458048197137\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 2 step\n",
            "Delta Q = 0.9017636434677152\n",
            "Q_table[1,0]_old = 0.016836690089483596\n",
            "Q_table[(1, 0)]_new = 0.0169166645482504\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 3 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.01781458048197137\n",
            "Q_table[(0, 2)]_new = 0.017852295420590126\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 4 step\n",
            "Delta Q = 0.9017673772466385\n",
            "Q_table[1,0]_old = 0.0169166645482504\n",
            "Q_table[(1, 0)]_new = 0.016992375340063783\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 5 step\n",
            "Delta Q = 0.9016636141386761\n",
            "Q_table[0,1]_old = 0.016305910677231437\n",
            "Q_table[(0, 1)]_new = 0.016338933748184393\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 6 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[5,1]_old = 0.01674862006121988\n",
            "Q_table[(5, 1)]_new = 0.016988704118221138\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 7 step\n",
            "Delta Q = 0.9016818817077039\n",
            "Q_table[10,3]_old = 0.015137165736022067\n",
            "Q_table[(10, 3)]_new = 0.015305330870123755\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 0 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017852295420590126\n",
            "Q_table[(0, 2)]_new = 0.017886238865347008\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 1 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[1,3]_old = 0.017382750359234804\n",
            "Q_table[(1, 3)]_new = 0.017463648310127217\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 2 step\n",
            "Delta Q = 0.9017707376476694\n",
            "Q_table[1,0]_old = 0.016992375340063783\n",
            "Q_table[(1, 0)]_new = 0.01706387545372676\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 3 step\n",
            "Delta Q = 0.9016818817077039\n",
            "Q_table[0,1]_old = 0.016338933748184393\n",
            "Q_table[(0, 1)]_new = 0.016386922081069847\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 4 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[5,1]_old = 0.016988704118221138\n",
            "Q_table[(5, 1)]_new = 0.017204779769522272\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 5 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[10,0]_old = 0.014511530113107903\n",
            "Q_table[(10, 0)]_new = 0.014975323164920359\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 0 step\n",
            "Delta Q = 0.9017707376476694\n",
            "Q_table[0,0]_old = 0.016910047091710245\n",
            "Q_table[(0, 0)]_new = 0.016989780030208575\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 1 step\n",
            "Delta Q = 0.9017707376476694\n",
            "Q_table[0,0]_old = 0.016989780030208575\n",
            "Q_table[(0, 0)]_new = 0.017061539674857074\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 2 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017886238865347008\n",
            "Q_table[(0, 2)]_new = 0.017916787965628202\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 3 step\n",
            "Delta Q = 0.9017737620085973\n",
            "Q_table[1,0]_old = 0.01706387545372676\n",
            "Q_table[(1, 0)]_new = 0.017131249916951276\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 4 step\n",
            "Delta Q = 0.9017737620085973\n",
            "Q_table[0,3]_old = 0.017390414460340856\n",
            "Q_table[(0, 3)]_new = 0.01742513502290396\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 5 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017916787965628202\n",
            "Q_table[(0, 2)]_new = 0.017944282155881276\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 6 step\n",
            "Delta Q = 0.9017764839334322\n",
            "Q_table[1,0]_old = 0.017131249916951276\n",
            "Q_table[(1, 0)]_new = 0.017194608858688395\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 7 step\n",
            "Delta Q = 0.9017764839334322\n",
            "Q_table[0,3]_old = 0.01742513502290396\n",
            "Q_table[(0, 3)]_new = 0.017459105454045814\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 8 step\n",
            "Delta Q = 0.9017032731971827\n",
            "Q_table[0,1]_old = 0.016386922081069847\n",
            "Q_table[(0, 1)]_new = 0.01645150307014557\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 9 step\n",
            "Delta Q = 0.9017764839334322\n",
            "Q_table[5,3]_old = 0.016804183218950504\n",
            "Q_table[(5, 3)]_new = 0.0169002488304877\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 10 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017944282155881276\n",
            "Q_table[(0, 2)]_new = 0.01796902692710904\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 11 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[1,3]_old = 0.017463648310127217\n",
            "Q_table[(1, 3)]_new = 0.01753645646593039\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 0 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.01796902692710904\n",
            "Q_table[(0, 2)]_new = 0.017991297221214033\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 0 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.017991297221214033\n",
            "Q_table[(0, 2)]_new = 0.018011340485908522\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 1 step\n",
            "Delta Q = 0.901783122708105\n",
            "Q_table[1,0]_old = 0.017194608858688395\n",
            "Q_table[(1, 0)]_new = 0.0172582706809245\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 2 step\n",
            "Delta Q = 0.9017032731971827\n",
            "Q_table[0,1]_old = 0.01645150307014557\n",
            "Q_table[(0, 1)]_new = 0.016509625960313717\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 3 step\n",
            "Delta Q = 0.9017032731971827\n",
            "Q_table[5,0]_old = 0.0156364969498405\n",
            "Q_table[(5, 0)]_new = 0.015776120452039157\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 4 step\n",
            "Delta Q = 0.9017032731971827\n",
            "Q_table[5,0]_old = 0.015776120452039157\n",
            "Q_table[(5, 0)]_new = 0.015901781604017947\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 5 step\n",
            "Delta Q = 0.901783122708105\n",
            "Q_table[5,3]_old = 0.0169002488304877\n",
            "Q_table[(5, 3)]_new = 0.016993346655543872\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 6 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.018011340485908522\n",
            "Q_table[(0, 2)]_new = 0.018029379424133563\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 7 step\n",
            "Delta Q = 0.9017849085629892\n",
            "Q_table[1,0]_old = 0.0172582706809245\n",
            "Q_table[(1, 0)]_new = 0.017317352175821272\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 8 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.018029379424133563\n",
            "Q_table[(0, 2)]_new = 0.0180456144685361\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 9 step\n",
            "Delta Q = 0.9017865158323851\n",
            "Q_table[1,0]_old = 0.017317352175821272\n",
            "Q_table[(1, 0)]_new = 0.017372132790624217\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 10 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.0180456144685361\n",
            "Q_table[(0, 2)]_new = 0.018060226008498385\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 11 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[1,3]_old = 0.01753645646593039\n",
            "Q_table[(1, 3)]_new = 0.017601983806153246\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 12 step\n",
            "Delta Q = 0.9017879623748414\n",
            "Q_table[1,0]_old = 0.017372132790624217\n",
            "Q_table[(1, 0)]_new = 0.017422881886403136\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 13 step\n",
            "Delta Q = 0.9017032731971827\n",
            "Q_table[0,1]_old = 0.016509625960313717\n",
            "Q_table[(0, 1)]_new = 0.01656193656146505\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 0 step\n",
            "Delta Q = 0.9017879623748414\n",
            "Q_table[0,3]_old = 0.017459105454045814\n",
            "Q_table[(0, 3)]_new = 0.01750115728348257\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 1 step\n",
            "Delta Q = 0.9017879623748414\n",
            "Q_table[0,0]_old = 0.017061539674857074\n",
            "Q_table[(0, 0)]_new = 0.017143348082212708\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 2 step\n",
            "Delta Q = 0.9017879623748414\n",
            "Q_table[0,3]_old = 0.01750115728348257\n",
            "Q_table[(0, 3)]_new = 0.017539003929975653\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 3 step\n",
            "Delta Q = 0.9017879623748414\n",
            "Q_table[0,3]_old = 0.017539003929975653\n",
            "Q_table[(0, 3)]_new = 0.017573065911819428\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 4 step\n",
            "Delta Q = 0.9017879623748414\n",
            "Q_table[0,3]_old = 0.017573065911819428\n",
            "Q_table[(0, 3)]_new = 0.017603721695478823\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 5 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.018060226008498385\n",
            "Q_table[(0, 2)]_new = 0.01807337639446444\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 0 step\n",
            "Delta Q = 0.9017032731971827\n",
            "Q_table[0,1]_old = 0.01656193656146505\n",
            "Q_table[(0, 1)]_new = 0.01660901610250125\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 1 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[5,1]_old = 0.017204779769522272\n",
            "Q_table[(5, 1)]_new = 0.01739924785569329\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 2 step\n",
            "Delta Q = 0.9017225255377137\n",
            "Q_table[10,3]_old = 0.015305330870123755\n",
            "Q_table[(10, 3)]_new = 0.015497323320825016\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 0 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.01807337639446444\n",
            "Q_table[(0, 2)]_new = 0.01808521174183389\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 1 step\n",
            "Delta Q = 0.9017904359624416\n",
            "Q_table[1,0]_old = 0.017422881886403136\n",
            "Q_table[(1, 0)]_new = 0.017471029660204376\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 2 step\n",
            "Delta Q = 0.9017904359624416\n",
            "Q_table[0,0]_old = 0.017143348082212708\n",
            "Q_table[(0, 0)]_new = 0.017219449236432992\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 3 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.01808521174183389\n",
            "Q_table[(0, 2)]_new = 0.018095863554466397\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 0 step\n",
            "Delta Q = 0.9017225255377137\n",
            "Q_table[0,1]_old = 0.01660901610250125\n",
            "Q_table[(0, 1)]_new = 0.016670640029964764\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 1 step\n",
            "Delta Q = 0.9017225255377137\n",
            "Q_table[5,0]_old = 0.015901781604017947\n",
            "Q_table[(5, 0)]_new = 0.01603412898132979\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 2 step\n",
            "Delta Q = 0.9017225255377137\n",
            "Q_table[5,0]_old = 0.01603412898132979\n",
            "Q_table[(5, 0)]_new = 0.016153241620910447\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 3 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[5,1]_old = 0.01739924785569329\n",
            "Q_table[(5, 1)]_new = 0.01757426913324721\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 4 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[10,0]_old = 0.014975323164920359\n",
            "Q_table[(10, 0)]_new = 0.01539273691155157\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 0 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.018095863554466397\n",
            "Q_table[(0, 2)]_new = 0.01810545018583565\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 1 step\n",
            "Delta Q = 0.9017924395683977\n",
            "Q_table[1,0]_old = 0.017471029660204376\n",
            "Q_table[(1, 0)]_new = 0.017516366262581667\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 2 step\n",
            "Delta Q = 0.9017924395683977\n",
            "Q_table[0,3]_old = 0.017603721695478823\n",
            "Q_table[(0, 3)]_new = 0.01763578909432867\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 3 step\n",
            "Delta Q = 0.9018191729868159\n",
            "Q_table[0,2]_old = 0.01810545018583565\n",
            "Q_table[(0, 2)]_new = 0.01811407815406798\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 4 step\n",
            "Delta Q = 0.9019189531846311\n",
            "Q_table[1,2]_old = 0.018375484715312064\n",
            "Q_table[(1, 2)]_new = 0.018456889428411956\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 5 step\n",
            "Delta Q = 0.9021011917812068\n",
            "Q_table[2,1]_old = 0.019383365501324214\n",
            "Q_table[(2, 1)]_new = 0.0195462207323986\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,2]_old = 0.0\n",
            "Q_table[(7, 2)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 0 step\n",
            "Delta Q = 0.9018272320534128\n",
            "Q_table[0,2]_old = 0.01811407815406798\n",
            "Q_table[(0, 2)]_new = 0.018129902392073963\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 1 step\n",
            "Delta Q = 0.9018272320534128\n",
            "Q_table[1,3]_old = 0.017601983806153246\n",
            "Q_table[(1, 3)]_new = 0.017669017478950704\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 0 step\n",
            "Delta Q = 0.9018272320534128\n",
            "Q_table[0,2]_old = 0.018129902392073963\n",
            "Q_table[(0, 2)]_new = 0.01814414420627935\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 0 step\n",
            "Delta Q = 0.9017962702764217\n",
            "Q_table[0,3]_old = 0.01763578909432867\n",
            "Q_table[(0, 3)]_new = 0.017668480461317457\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 1 step\n",
            "Delta Q = 0.9018272320534128\n",
            "Q_table[0,2]_old = 0.01814414420627935\n",
            "Q_table[(0, 2)]_new = 0.018156961839064196\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 0 step\n",
            "Delta Q = 0.9017398526441915\n",
            "Q_table[0,1]_old = 0.016670640029964764\n",
            "Q_table[(0, 1)]_new = 0.01674342867115976\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 0 step\n",
            "Delta Q = 0.9018272320534128\n",
            "Q_table[0,2]_old = 0.018156961839064196\n",
            "Q_table[(0, 2)]_new = 0.01816849770857056\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 1 step\n",
            "Delta Q = 0.9018272320534128\n",
            "Q_table[1,3]_old = 0.017669017478950704\n",
            "Q_table[(1, 3)]_new = 0.017729347784468417\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 2 step\n",
            "Delta Q = 0.9019350758525074\n",
            "Q_table[1,2]_old = 0.018456889428411956\n",
            "Q_table[(1, 2)]_new = 0.018546276338078222\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 3 step\n",
            "Delta Q = 0.9019350758525074\n",
            "Q_table[2,3]_old = 0.017103994187153443\n",
            "Q_table[(2, 3)]_new = 0.01732867062094556\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 4 step\n",
            "Delta Q = 0.9013787401926827\n",
            "Q_table[2,2]_old = 0.010888149531362672\n",
            "Q_table[(2, 2)]_new = 0.011178074770909055\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 5 step\n",
            "Delta Q = 0.9005369504776691\n",
            "Q_table[3,2]_old = 0.0018953740683864374\n",
            "Q_table[(3, 2)]_new = 0.0022427871392168503\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 6 step\n",
            "Delta Q = 0.9005369504776691\n",
            "Q_table[4,3]_old = 0.0009789154216970366\n",
            "Q_table[(4, 3)]_new = 0.0014179743571963897\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 7 step\n",
            "Delta Q = 0.9013787401926827\n",
            "Q_table[4,0]_old = 0.005423742198677341\n",
            "Q_table[(4, 0)]_new = 0.0062601081714922565\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 8 step\n",
            "Delta Q = 0.9019350758525074\n",
            "Q_table[3,0]_old = 0.013926668612956055\n",
            "Q_table[(3, 0)]_new = 0.014469077604167912\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 9 step\n",
            "Delta Q = 0.9021011917812068\n",
            "Q_table[2,1]_old = 0.0195462207323986\n",
            "Q_table[(2, 1)]_new = 0.019692790440365548\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 10 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[7,3]_old = 0.011673816343710546\n",
            "Q_table[(7, 3)]_new = 0.01245602096293568\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 11 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[2,3]_old = 0.01732867062094556\n",
            "Q_table[(2, 3)]_new = 0.017545389812447194\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 12 step\n",
            "Delta Q = 0.9018360813574697\n",
            "Q_table[2,0]_old = 0.015963989147921492\n",
            "Q_table[(2, 0)]_new = 0.016203671590599086\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 13 step\n",
            "Delta Q = 0.9018360813574697\n",
            "Q_table[1,3]_old = 0.017729347784468417\n",
            "Q_table[(1, 3)]_new = 0.01779249436349132\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 14 step\n",
            "Delta Q = 0.9017986812731486\n",
            "Q_table[1,0]_old = 0.017516366262581667\n",
            "Q_table[(1, 0)]_new = 0.017563410909471985\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 15 step\n",
            "Delta Q = 0.9017986812731486\n",
            "Q_table[0,3]_old = 0.017668480461317457\n",
            "Q_table[(0, 3)]_new = 0.017700313688334197\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 16 step\n",
            "Delta Q = 0.9017986812731486\n",
            "Q_table[0,3]_old = 0.017700313688334197\n",
            "Q_table[(0, 3)]_new = 0.017728963592649263\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 17 step\n",
            "Delta Q = 0.9017986812731486\n",
            "Q_table[0,0]_old = 0.017219449236432992\n",
            "Q_table[(0, 0)]_new = 0.01729618558593818\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 18 step\n",
            "Delta Q = 0.9017986812731486\n",
            "Q_table[0,3]_old = 0.017728963592649263\n",
            "Q_table[(0, 3)]_new = 0.017754748506532823\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 19 step\n",
            "Delta Q = 0.9018360813574697\n",
            "Q_table[0,2]_old = 0.01816849770857056\n",
            "Q_table[(0, 2)]_new = 0.01818772929518325\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 20 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[1,2]_old = 0.018546276338078222\n",
            "Q_table[(1, 2)]_new = 0.018641234957866588\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 21 step\n",
            "Delta Q = 0.9014324386828126\n",
            "Q_table[2,2]_old = 0.011178074770909055\n",
            "Q_table[(2, 2)]_new = 0.011492705976630773\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 22 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[3,0]_old = 0.014469077604167912\n",
            "Q_table[(3, 0)]_new = 0.01497175609734731\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 23 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[2,3]_old = 0.017545389812447194\n",
            "Q_table[(2, 3)]_new = 0.017740437084798666\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 24 step\n",
            "Delta Q = 0.9018454822608288\n",
            "Q_table[2,0]_old = 0.016203671590599086\n",
            "Q_table[(2, 0)]_new = 0.01642878669236797\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 25 step\n",
            "Delta Q = 0.9018454822608288\n",
            "Q_table[1,3]_old = 0.01779249436349132\n",
            "Q_table[(1, 3)]_new = 0.01785872718797098\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 26 step\n",
            "Delta Q = 0.9018454822608288\n",
            "Q_table[1,3]_old = 0.01785872718797098\n",
            "Q_table[(1, 3)]_new = 0.017918336730002673\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 27 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[1,2]_old = 0.018641234957866588\n",
            "Q_table[(1, 2)]_new = 0.01872669771567612\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 28 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[2,3]_old = 0.017740437084798666\n",
            "Q_table[(2, 3)]_new = 0.01791597962991499\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 29 step\n",
            "Delta Q = 0.9014822038536374\n",
            "Q_table[2,2]_old = 0.011492705976630773\n",
            "Q_table[(2, 2)]_new = 0.01182563923260508\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 30 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 0 step\n",
            "Delta Q = 0.9018005852002232\n",
            "Q_table[0,0]_old = 0.01729618558593818\n",
            "Q_table[(0, 0)]_new = 0.017367152227567503\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 1 step\n",
            "Delta Q = 0.9017398526441915\n",
            "Q_table[0,1]_old = 0.01674342867115976\n",
            "Q_table[(0, 1)]_new = 0.01680893844823526\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 2 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[5,1]_old = 0.01757426913324721\n",
            "Q_table[(5, 1)]_new = 0.017731788283045734\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 3 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[10,0]_old = 0.01539273691155157\n",
            "Q_table[(10, 0)]_new = 0.01576840928351966\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 4 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[10,0]_old = 0.01576840928351966\n",
            "Q_table[(10, 0)]_new = 0.01610651441829094\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 5 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[10,0]_old = 0.01610651441829094\n",
            "Q_table[(10, 0)]_new = 0.01641080903958509\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 6 step\n",
            "Delta Q = 0.9017554470400215\n",
            "Q_table[10,3]_old = 0.015497323320825016\n",
            "Q_table[(10, 3)]_new = 0.015703038028764042\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 7 step\n",
            "Delta Q = 0.9018005852002232\n",
            "Q_table[5,3]_old = 0.016993346655543872\n",
            "Q_table[(5, 3)]_new = 0.017094597190212626\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 8 step\n",
            "Delta Q = 0.9018539430738519\n",
            "Q_table[0,2]_old = 0.01818772929518325\n",
            "Q_table[(0, 2)]_new = 0.01822289943951686\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 9 step\n",
            "Delta Q = 0.9018539430738519\n",
            "Q_table[1,3]_old = 0.017918336730002673\n",
            "Q_table[(1, 3)]_new = 0.017980446130854342\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 10 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[1,2]_old = 0.01872669771567612\n",
            "Q_table[(1, 2)]_new = 0.018803614197704696\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 11 step\n",
            "Delta Q = 0.9018615578055728\n",
            "Q_table[2,0]_old = 0.01642878669236797\n",
            "Q_table[(2, 0)]_new = 0.01664746582870394\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 0 step\n",
            "Delta Q = 0.9018040670445122\n",
            "Q_table[0,3]_old = 0.017754748506532823\n",
            "Q_table[(0, 3)]_new = 0.017783340700391708\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 1 step\n",
            "Delta Q = 0.9018615578055728\n",
            "Q_table[0,2]_old = 0.01822289943951686\n",
            "Q_table[(0, 2)]_new = 0.01826216730113794\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 2 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[1,2]_old = 0.018803614197704696\n",
            "Q_table[(1, 2)]_new = 0.018872839031530416\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 3 step\n",
            "Delta Q = 0.9018684110641215\n",
            "Q_table[2,0]_old = 0.01664746582870394\n",
            "Q_table[(2, 0)]_new = 0.016851130309955057\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 4 step\n",
            "Delta Q = 0.9018684110641215\n",
            "Q_table[1,3]_old = 0.017980446130854342\n",
            "Q_table[(1, 3)]_new = 0.018050812581890417\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 5 step\n",
            "Delta Q = 0.9018684110641215\n",
            "Q_table[1,3]_old = 0.018050812581890417\n",
            "Q_table[(1, 3)]_new = 0.018114142387822888\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 6 step\n",
            "Delta Q = 0.9018079545628127\n",
            "Q_table[1,0]_old = 0.017563410909471985\n",
            "Q_table[(1, 0)]_new = 0.01761502438133744\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 7 step\n",
            "Delta Q = 0.9018079545628127\n",
            "Q_table[0,3]_old = 0.017783340700391708\n",
            "Q_table[(0, 3)]_new = 0.01781296119316519\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 8 step\n",
            "Delta Q = 0.9017554470400215\n",
            "Q_table[0,1]_old = 0.01680893844823526\n",
            "Q_table[(0, 1)]_new = 0.016883491643433262\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 0 step\n",
            "Delta Q = 0.9018079545628127\n",
            "Q_table[0,0]_old = 0.017367152227567503\n",
            "Q_table[(0, 0)]_new = 0.017438391567623408\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 1 step\n",
            "Delta Q = 0.9018684110641215\n",
            "Q_table[0,2]_old = 0.01826216730113794\n",
            "Q_table[(0, 2)]_new = 0.018304361635145656\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 2 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[1,2]_old = 0.018872839031530416\n",
            "Q_table[(1, 2)]_new = 0.018935141381973563\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 3 step\n",
            "Delta Q = 0.9014822038536374\n",
            "Q_table[2,2]_old = 0.01182563923260508\n",
            "Q_table[(2, 2)]_new = 0.012125279162981957\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 0 step\n",
            "Delta Q = 0.9018121318018795\n",
            "Q_table[0,0]_old = 0.017438391567623408\n",
            "Q_table[(0, 0)]_new = 0.017506684212740486\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 1 step\n",
            "Delta Q = 0.9017554470400215\n",
            "Q_table[0,1]_old = 0.016883491643433262\n",
            "Q_table[(0, 1)]_new = 0.016950589519111464\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 2 step\n",
            "Delta Q = 0.9017554470400215\n",
            "Q_table[5,0]_old = 0.016153241620910447\n",
            "Q_table[(5, 0)]_new = 0.016293364498840928\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 3 step\n",
            "Delta Q = 0.9018121318018795\n",
            "Q_table[5,3]_old = 0.017094597190212626\n",
            "Q_table[(5, 3)]_new = 0.017197269273070782\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 4 step\n",
            "Delta Q = 0.9017554470400215\n",
            "Q_table[0,1]_old = 0.016950589519111464\n",
            "Q_table[(0, 1)]_new = 0.017010977607221846\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 5 step\n",
            "Delta Q = 0.9017554470400215\n",
            "Q_table[5,0]_old = 0.016293364498840928\n",
            "Q_table[(5, 0)]_new = 0.016419475088978362\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 6 step\n",
            "Delta Q = 0.9019149460631233\n",
            "Q_table[5,1]_old = 0.017731788283045734\n",
            "Q_table[(5, 1)]_new = 0.017873555517864407\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 7 step\n",
            "Delta Q = 0.9024229198039879\n",
            "Q_table[10,2]_old = 0.01934288952649743\n",
            "Q_table[(10, 2)]_new = 0.019831520377835588\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 8 step\n",
            "Delta Q = 0.9019633205174058\n",
            "Q_table[11,0]_old = 0.01252091935504865\n",
            "Q_table[(11, 0)]_new = 0.013232147936949509\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 0 step\n",
            "Delta Q = 0.9018121318018795\n",
            "Q_table[0,3]_old = 0.01781296119316519\n",
            "Q_table[(0, 3)]_new = 0.01784379687572809\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 1 step\n",
            "Delta Q = 0.9017694819962686\n",
            "Q_table[0,1]_old = 0.017010977607221846\n",
            "Q_table[(0, 1)]_new = 0.01707936184276824\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 2 step\n",
            "Delta Q = 0.9019633205174058\n",
            "Q_table[5,1]_old = 0.017873555517864407\n",
            "Q_table[(5, 1)]_new = 0.01804952048348369\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 3 step\n",
            "Delta Q = 0.9017869025278649\n",
            "Q_table[10,3]_old = 0.015703038028764042\n",
            "Q_table[(10, 3)]_new = 0.015919636753752523\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 4 step\n",
            "Delta Q = 0.9019633205174058\n",
            "Q_table[5,1]_old = 0.01804952048348369\n",
            "Q_table[(5, 1)]_new = 0.018207888952541045\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 5 step\n",
            "Delta Q = 0.9024229198039879\n",
            "Q_table[10,2]_old = 0.019831520377835588\n",
            "Q_table[(10, 2)]_new = 0.020271288144039924\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 6 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[11,1]_old = 0.02447393741401917\n",
            "Q_table[(11, 1)]_new = 0.02601819099667836\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 7 step\n",
            "Delta Q = 0.9075830640831\n",
            "Q_table[16,2]_old = 0.026363853082201343\n",
            "Q_table[(16, 2)]_new = 0.03131053185708121\n",
            "We are on 16 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 8 step\n",
            "Delta Q = 0.9039916473240611\n",
            "Q_table[17,0]_old = 0.019922211955739927\n",
            "Q_table[(17, 0)]_new = 0.021921638084227042\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 9 step\n",
            "Delta Q = 0.9109254840185799\n",
            "Q_table[16,1]_old = 0.040319669940011196\n",
            "Q_table[(16, 1)]_new = 0.04721318696458998\n",
            "We are on 16 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 10 step\n",
            "Delta Q = 0.926829\n",
            "Q_table[21,2]_old = 0.11035842443010001\n",
            "Q_table[(21, 2)]_new = 0.12615158198709003\n",
            "We are on 21 state\n",
            "And now we are on 22 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 11 step\n",
            "Delta Q = 0.9124890066167219\n",
            "Q_table[22,0]_old = 0.027224447635459805\n",
            "Q_table[(22, 0)]_new = 0.036991009488635734\n",
            "We are on 22 state\n",
            "And now we are on 21 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 12 step\n",
            "Delta Q = 0.9046741055094945\n",
            "Q_table[21,3]_old = 0.013673773762215083\n",
            "Q_table[(21, 3)]_new = 0.016980501895487984\n",
            "We are on 21 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 13 step\n",
            "Delta Q = 0.9075830640831\n",
            "Q_table[16,2]_old = 0.03131053185708121\n",
            "Q_table[(16, 2)]_new = 0.03576254275447309\n",
            "We are on 16 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 14 step\n",
            "Delta Q = 0.9046741055094945\n",
            "Q_table[17,0]_old = 0.021921638084227042\n",
            "Q_table[(17, 0)]_new = 0.024403579785298748\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 15 step\n",
            "Delta Q = 0.9025758009086712\n",
            "Q_table[16,3]_old = 0.00912094974483902\n",
            "Q_table[(16, 3)]_new = 0.010784655679026277\n",
            "We are on 16 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 16 step\n",
            "Delta Q = 0.9032041623185824\n",
            "Q_table[11,2]_old = 0.017786147407033638\n",
            "Q_table[(11, 2)]_new = 0.019211694984912615\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 17 step\n",
            "Delta Q = 0.9021011917812068\n",
            "Q_table[12,3]_old = 0.011260914401928663\n",
            "Q_table[(12, 3)]_new = 0.012236014742942601\n",
            "We are on 12 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 18 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[7,3]_old = 0.01245602096293568\n",
            "Q_table[(7, 3)]_new = 0.013160005120238303\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 19 step\n",
            "Delta Q = 0.9014822038536374\n",
            "Q_table[2,2]_old = 0.012125279162981957\n",
            "Q_table[(2, 2)]_new = 0.012394955100321146\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 20 step\n",
            "Delta Q = 0.9014822038536374\n",
            "Q_table[3,3]_old = 0.0037513706252985655\n",
            "Q_table[(3, 3)]_new = 0.004858437416406093\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 21 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 0 step\n",
            "Delta Q = 0.9018025810063016\n",
            "Q_table[0,1]_old = 0.01707936184276824\n",
            "Q_table[(0, 1)]_new = 0.01717400666479298\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 1 step\n",
            "Delta Q = 0.9018025810063016\n",
            "Q_table[5,0]_old = 0.016419475088978362\n",
            "Q_table[(5, 0)]_new = 0.01658010858638209\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 0 step\n",
            "Delta Q = 0.9018121318018795\n",
            "Q_table[0,0]_old = 0.017506684212740486\n",
            "Q_table[(0, 0)]_new = 0.017568147593345858\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 1 step\n",
            "Delta Q = 0.9018121318018795\n",
            "Q_table[0,3]_old = 0.01784379687572809\n",
            "Q_table[(0, 3)]_new = 0.0178715489900347\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 2 step\n",
            "Delta Q = 0.9018745789968154\n",
            "Q_table[0,2]_old = 0.018304361635145656\n",
            "Q_table[(0, 2)]_new = 0.018348504468446474\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 3 step\n",
            "Delta Q = 0.9018165019423762\n",
            "Q_table[1,0]_old = 0.01761502438133744\n",
            "Q_table[(1, 0)]_new = 0.017670023885579898\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 4 step\n",
            "Delta Q = 0.9018165019423762\n",
            "Q_table[0,0]_old = 0.017568147593345858\n",
            "Q_table[(0, 0)]_new = 0.017627834776387474\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 5 step\n",
            "Delta Q = 0.9018165019423762\n",
            "Q_table[0,3]_old = 0.0178715489900347\n",
            "Q_table[(0, 3)]_new = 0.017900896033407433\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 6 step\n",
            "Delta Q = 0.9018025810063016\n",
            "Q_table[0,1]_old = 0.01717400666479298\n",
            "Q_table[(0, 1)]_new = 0.017259187004615244\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 0 step\n",
            "Delta Q = 0.9018745789968154\n",
            "Q_table[0,2]_old = 0.018348504468446474\n",
            "Q_table[(0, 2)]_new = 0.01838823301841721\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 1 step\n",
            "Delta Q = 0.9019495862535962\n",
            "Q_table[1,2]_old = 0.018935141381973563\n",
            "Q_table[(1, 2)]_new = 0.018991213497372397\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 2 step\n",
            "Delta Q = 0.9018801301362399\n",
            "Q_table[2,0]_old = 0.016851130309955057\n",
            "Q_table[(2, 0)]_new = 0.01704614741519942\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 3 step\n",
            "Delta Q = 0.9018204350688234\n",
            "Q_table[1,0]_old = 0.017670023885579898\n",
            "Q_table[(1, 0)]_new = 0.017723456565845213\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 4 step\n",
            "Delta Q = 0.9018204350688234\n",
            "Q_table[0,3]_old = 0.017900896033407433\n",
            "Q_table[(0, 3)]_new = 0.017931241498889992\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 5 step\n",
            "Delta Q = 0.9018801301362399\n",
            "Q_table[0,2]_old = 0.01838823301841721\n",
            "Q_table[(0, 2)]_new = 0.018429539852815355\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 0 step\n",
            "Delta Q = 0.9018025810063016\n",
            "Q_table[0,1]_old = 0.017259187004615244\n",
            "Q_table[(0, 1)]_new = 0.017335849310455283\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 1 step\n",
            "Delta Q = 0.90200685752626\n",
            "Q_table[5,1]_old = 0.018207888952541045\n",
            "Q_table[(5, 1)]_new = 0.018393957583546894\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 2 step\n",
            "Delta Q = 0.9025758009086712\n",
            "Q_table[10,2]_old = 0.020271288144039924\n",
            "Q_table[(10, 2)]_new = 0.02081996023830709\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,3]_old = 0.0\n",
            "Q_table[(11, 3)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-lbtJrw_AV7"
      },
      "source": [
        "7. Kode di atas mengiterasi melalui serangkaian episode, melakukan langkah-langkah dalam setiap episode, memperbarui nilai delta Q sesuai dengan aturan pembelajaran Q-learning, dan menyimpan total reward dari setiap episode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY_gWcsHzKeL",
        "outputId": "0aab2be2-cf47-4650-ad67-57d197a272d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (67.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2IpwgIzzO-b"
      },
      "outputs": [],
      "source": [
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s55KD3Bn_LjU"
      },
      "source": [
        "8. Python untuk menginstal paket imageio dan imageio_ffmpeg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C60ijuTtzPwW"
      },
      "outputs": [],
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht2ySePH_cs-"
      },
      "source": [
        "9. Fungsi `record_video` merekam video dari lingkungan permainan menggunakan tabel Q, dengan mengambil tindakan berdasarkan nilai maksimum dari tabel Q untuk setiap keadaan, dan menyimpan gambar dari setiap iterasi ke dalam daftar gambar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "q3PlU4H9zRW0",
        "outputId": "8ce37e8e-0d6e-4977-dd93-09d7136f2102"
      },
      "outputs": [
        {
          "data": {
            "image/gif": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VhOWlLd_eM2"
      },
      "source": [
        "10. Kode di atas merekam video dari lingkungan `env` menggunakan tabel Q `q_table`, kemudian menyimpannya sebagai file GIF dengan nama `replay.gif` pada path `/content/`. Video tersebut kemudian ditampilkan menggunakan IPython display."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
